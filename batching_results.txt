PS C:\Users\franj\CT-DRL-MA> python -m tests.BooleanStorage.stress_test
Starting Container Placement Performance Tests...

🚀 Quick Stress Test
🚛 Starting Container Placement Stress Test 🚛
============================================================
Yard Configuration: {'n_rows': 5, 'n_bays': 15, 'n_tiers': 3, 'split_factor': 4}
Test Sizes: [100, 500, 1000]
============================================================

📦 Testing with 100 containers...
Results for 100 containers:
  ✅ Successfully placed: 97/100 (97.0%)
  ⏱️  Average search time: 0.199 ms
  ⏱️  Max search time: 1.456 ms
  🔍 Search operations/sec: 5023.8
  💾 Memory usage: 0.2 MB (peak: 0.2 MB)
  📊 Yard utilization: 43.1%
  🕐 Total test time: 0.04 seconds

📦 Testing with 500 containers...
  Processed 100/500 containers...
  Processed 200/500 containers...
  Processed 300/500 containers...
  Processed 400/500 containers...
Results for 500 containers:
  ✅ Successfully placed: 493/500 (98.6%)
  ⏱️  Average search time: 0.166 ms
  ⏱️  Max search time: 0.720 ms
  🔍 Search operations/sec: 6032.1
  💾 Memory usage: 0.3 MB (peak: 0.3 MB)
  📊 Yard utilization: 219.1%
  🕐 Total test time: 0.15 seconds

📦 Testing with 1000 containers...
  Processed 100/1000 containers...
  Processed 200/1000 containers...
  Processed 300/1000 containers...
  Processed 400/1000 containers...
  Processed 500/1000 containers...
  Processed 600/1000 containers...
  Processed 700/1000 containers...
  Processed 800/1000 containers...
  Processed 900/1000 containers...
Results for 1000 containers:
  ✅ Successfully placed: 987/1000 (98.7%)
  ⏱️  Average search time: 0.182 ms
  ⏱️  Max search time: 2.486 ms
  🔍 Search operations/sec: 5487.9
  💾 Memory usage: 0.5 MB (peak: 0.5 MB)
  📊 Yard utilization: 438.7%
  🕐 Total test time: 0.30 seconds

============================================================
📊 STRESS TEST SUMMARY
============================================================
Containers   Success%   Avg Search(ms)  Ops/sec    Memory(MB)   Time(s)
---------------------------------------------------------------------------
100          97.0       0.199           5023.8     0.2          0.04
500          98.6       0.166           6032.1     0.3          0.15
1000         98.7       0.182           5487.9     0.5          0.30

🔬 Performance Scaling Analysis:
  Base case (100 containers): 0.199 ms avg search
  500 containers: 0.166 ms (0.83x vs 5.0x linear)
  1000 containers: 0.182 ms (0.92x vs 10.0x linear)

💡 Recommendations:
  ⚠️  Maximum search time: 2.486 ms - consider batching for large operations
  ✅ Performance is excellent - no batching needed
  ✅ Memory usage is reasonable: 0.5 MB peak

================================================================================

🏭 Full Scale Stress Test
🚛 Starting Container Placement Stress Test 🚛
============================================================
Yard Configuration: {'n_rows': 8, 'n_bays': 40, 'n_tiers': 5, 'split_factor': 4}
Test Sizes: [100, 500, 1000, 5000]
============================================================

📦 Testing with 100 containers...
Results for 100 containers:
  ✅ Successfully placed: 94/100 (94.0%)
  ⏱️  Average search time: 0.354 ms
  ⏱️  Max search time: 2.004 ms
  🔍 Search operations/sec: 2826.3
  💾 Memory usage: 1.0 MB (peak: 1.0 MB)
  📊 Yard utilization: 5.9%
  🕐 Total test time: 0.12 seconds

📦 Testing with 500 containers...
  Processed 100/500 containers...
  Processed 200/500 containers...
  Processed 300/500 containers...
  Processed 400/500 containers...
Results for 500 containers:
  ✅ Successfully placed: 493/500 (98.6%)
  ⏱️  Average search time: 0.333 ms
  ⏱️  Max search time: 4.861 ms
  🔍 Search operations/sec: 3002.1
  💾 Memory usage: 1.2 MB (peak: 1.2 MB)
  📊 Yard utilization: 30.8%
  🕐 Total test time: 0.30 seconds

📦 Testing with 1000 containers...
  Processed 100/1000 containers...
  Processed 200/1000 containers...
  Processed 300/1000 containers...
  Processed 400/1000 containers...
  Processed 500/1000 containers...
  Processed 600/1000 containers...
  Processed 700/1000 containers...
  Processed 800/1000 containers...
  Processed 900/1000 containers...
Results for 1000 containers:
  ⏱️  Max search time: 2.127 ms
  🔍 Search operations/sec: 3210.0
  💾 Memory usage: 1.3 MB (peak: 1.3 MB)
  📊 Yard utilization: 61.9%
  🕐 Total test time: 0.49 seconds

📦 Testing with 5000 containers...
  Processed 100/5000 containers...
  Processed 200/5000 containers...
  Processed 300/5000 containers...
  Processed 400/5000 containers...
  Processed 500/5000 containers...
  Processed 600/5000 containers...
  Processed 700/5000 containers...
  Processed 800/5000 containers...
  Processed 900/5000 containers...
  Processed 1000/5000 containers...
  Processed 1100/5000 containers...
  Processed 1200/5000 containers...
  Processed 1300/5000 containers...
  Processed 1400/5000 containers...
  Processed 1500/5000 containers...
  Processed 1600/5000 containers...
  Processed 1700/5000 containers...
  Processed 1800/5000 containers...
  Processed 1900/5000 containers...
  Processed 2000/5000 containers...
  Processed 2100/5000 containers...
  Processed 2200/5000 containers...
  Processed 2300/5000 containers...
  Processed 2400/5000 containers...
  Processed 2500/5000 containers...
  Processed 2600/5000 containers...
  Processed 2700/5000 containers...
  Processed 2800/5000 containers...
  Processed 2900/5000 containers...
  Processed 3000/5000 containers...
  Processed 3100/5000 containers...
  Processed 3200/5000 containers...
  Processed 3300/5000 containers...
  Processed 3400/5000 containers...
  Processed 3500/5000 containers...
  Processed 3600/5000 containers...
  Processed 3700/5000 containers...
  Processed 3800/5000 containers...
  Processed 3900/5000 containers...
  Processed 4000/5000 containers...
  Processed 4100/5000 containers...
  Processed 4200/5000 containers...
  Processed 4300/5000 containers...
  Processed 4400/5000 containers...
  Processed 4500/5000 containers...
  Processed 4600/5000 containers...
  Processed 4700/5000 containers...
  Processed 4800/5000 containers...
  Processed 4900/5000 containers...
Results for 5000 containers:
  ✅ Successfully placed: 4959/5000 (99.2%)
  ⏱️  Average search time: 0.323 ms
  ⏱️  Max search time: 6.389 ms
  🔍 Search operations/sec: 3095.4
  💾 Memory usage: 2.7 MB (peak: 2.8 MB)
  📊 Yard utilization: 309.9%
  🕐 Total test time: 2.23 seconds

============================================================
📊 STRESS TEST SUMMARY
============================================================
Containers   Success%   Avg Search(ms)  Ops/sec    Memory(MB)   Time(s)
---------------------------------------------------------------------------
100          94.0       0.354           2826.3     1.0          0.12
500          98.6       0.333           3002.1     1.2          0.30
1000         99.1       0.312           3210.0     1.3          0.49
5000         99.2       0.323           3095.4     2.7          2.23

🔬 Performance Scaling Analysis:
  Base case (100 containers): 0.354 ms avg search
  500 containers: 0.333 ms (0.94x vs 5.0x linear)
  1000 containers: 0.312 ms (0.88x vs 10.0x linear)
  5000 containers: 0.323 ms (0.91x vs 50.0x linear)

💡 Recommendations:
  ⚠️  Maximum search time: 6.389 ms - consider batching for large operations
  ✅ Performance is excellent - no batching needed
  ✅ Memory usage is reasonable: 2.8 MB peak

================================================================================

⚡ Running Simple Batch Optimization Test...
⚡ Simple Batch Optimization Test
🚀 Simple Batch Optimization Benchmark
============================================================

🔧 Testing 500 containers...
Benchmarking 500 containers (simple approach)...
  Sequential: 0.0613s (8160 ops/sec)
  Batch:      1.6103s (311 ops/sec)
  Speedup:    0.04x
  Match:      ✅

🔧 Testing 1000 containers...
Benchmarking 1000 containers (simple approach)...
  Sequential: 0.1218s (8212 ops/sec)
  Batch:      2.5491s (392 ops/sec)
  Speedup:    0.05x
  Match:      ✅

🔧 Testing 2000 containers...
Benchmarking 2000 containers (simple approach)...
  Sequential: 0.2334s (8569 ops/sec)
  Batch:      4.7563s (420 ops/sec)
  Speedup:    0.05x
  Match:      ✅

🔧 Testing 5000 containers...
Benchmarking 5000 containers (simple approach)...
  Sequential: 0.5692s (8784 ops/sec)
  Batch:      10.5092s (476 ops/sec)
  Speedup:    0.05x
  Match:      ✅

📊 Simple Optimization Summary:
  500 containers: 0.04x speedup
  1000 containers: 0.05x speedup
  2000 containers: 0.05x speedup
  5000 containers: 0.05x speedup

📊 Performance Comparison Summary:
============================================================
Original placement test (5000 containers): 2.23s
Sequential search only: 0.57s
Batch search only: 10.51s
Search speedup: 0.05x
❌ Batch optimization slower than sequential
💡 Recommendation: Use sequential for this workload

================================================================================
🏁 All tests completed!



CODE USED:

import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import time
from typing import List, Dict, Tuple

# Add ONLY these 2 methods to your BooleanStorageYard class:

    def batch_search_simple(self, container_specs: List[Dict], max_workers: int = None) -> List[List[Tuple]]:
        """
        Simple parallel batch search - just parallelizes search_insertion_position.
        No fancy grouping, no vectorization, just raw parallelism.
        
        Args:
            container_specs: List of dicts with keys: bay, goods, container_type, max_proximity
            max_workers: Number of processes (default: CPU count)
        
        Returns:
            List of results in same order as input
        """
        if not container_specs:
            return []
        
        if max_workers is None:
            max_workers = mp.cpu_count()
        
        # For small batches, sequential is faster due to overhead
        if len(container_specs) < max_workers * 2:
            return [self.search_insertion_position(spec['bay'], spec['goods'], 
                                                spec['container_type'], spec['max_proximity']) 
                    for spec in container_specs]
        
        # Parallel processing for larger batches
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # Submit all jobs
            futures = [
                executor.submit(_search_worker, self, spec['bay'], spec['goods'], 
                            spec['container_type'], spec['max_proximity'])
                for spec in container_specs
            ]
            
            # Collect results in order
            results = [future.result() for future in futures]
        
        return results

    def benchmark_simple_batch(self, container_specs: List[Dict]) -> Dict:
        """Simple benchmark of the batch method."""
        print(f"Benchmarking {len(container_specs)} containers (simple approach)...")
        
        # Sequential timing
        start = time.perf_counter()
        sequential_results = [self.search_insertion_position(spec['bay'], spec['goods'], 
                                                            spec['container_type'], spec['max_proximity']) 
                            for spec in container_specs]
        sequential_time = time.perf_counter() - start
        
        # Batch timing
        start = time.perf_counter()
        batch_results = self.batch_search_simple(container_specs)
        batch_time = time.perf_counter() - start
        
        # Verify results match
        results_match = len(sequential_results) == len(batch_results)
        if results_match:
            for seq, batch in zip(sequential_results, batch_results):
                if sorted(seq) != sorted(batch):
                    results_match = False
                    break
        
        speedup = sequential_time / batch_time if batch_time > 0 else 0
        
        return {
            'sequential_time': sequential_time,
            'batch_time': batch_time,
            'speedup': speedup,
            'results_match': results_match,
            'sequential_ops_per_sec': len(container_specs) / sequential_time,
            'batch_ops_per_sec': len(container_specs) / batch_time
        }

# Global worker function (must be at module level for multiprocessing)
def _search_worker(yard:BooleanStorageYard, bay, goods, container_type, max_proximity):
    """Worker function for parallel search - keeps it simple."""
    return yard.search_insertion_position(bay, goods, container_type, max_proximity)



stress_Test.py


def run_simple_batch_optimization_test():
    """
    Run simple batch optimization test using the existing ContainerPlacementStressTest architecture.
    Tests direct parallelization of search_insertion_position without complex optimizations.
    """
    # Same realistic configuration as full test
    realistic_config = {
        'n_rows': 8,
        'n_bays': 40,
        'n_tiers': 5,
        'split_factor': 4
    }
    
    print("⚡ Simple Batch Optimization Test")
    
    # Create tester instance
    tester = ContainerPlacementStressTest(realistic_config)
    
    # Run the simple optimization benchmark
    optimization_results = tester.run_simple_optimization_benchmark([500, 1000, 2000, 5000])
    
    return optimization_results

# Update your main section to include the simple batch test:
if __name__ == "__main__":
    # Run existing tests first
    print("Starting Container Placement Performance Tests...\n")
    
    # Quick test
    quick_results = run_quick_stress_test()
    
    print("\n" + "="*80 + "\n")
    
    # Full test
    full_results = run_full_stress_test()
    
    print("\n" + "="*80 + "\n")
    
    # NEW: Simple batch optimization test
    print("⚡ Running Simple Batch Optimization Test...")
    simple_batch_results = run_simple_batch_optimization_test()
    
    # Compare results
    print("\n📊 Performance Comparison Summary:")
    print("="*60)
    
    # Get 5000 container results for comparison
    if 5000 in full_results and 5000 in simple_batch_results:
        original_time = full_results[5000]['total_test_time']
        sequential_search_time = simple_batch_results[5000]['sequential_time'] 
        batch_search_time = simple_batch_results[5000]['batch_time']
        speedup = simple_batch_results[5000]['speedup']
        
        print(f"Original placement test (5000 containers): {original_time:.2f}s")
        print(f"Sequential search only: {sequential_search_time:.2f}s") 
        print(f"Batch search only: {batch_search_time:.2f}s")
        print(f"Search speedup: {speedup:.2f}x")
        
        if speedup > 1.0:
            print(f"✅ Batch optimization successful!")
            estimated_improvement = original_time * (batch_search_time / sequential_search_time)
            print(f"📈 Estimated full test improvement: {original_time:.2f}s → {estimated_improvement:.2f}s")
        else:
            print(f"❌ Batch optimization slower than sequential")
            print(f"💡 Recommendation: Use sequential for this workload")
    
    print("\n" + "="*80)
    print("🏁 All tests completed!")

        def run_simple_optimization_benchmark(self, container_counts: List[int] = None) -> Dict:
        """
        Simple optimization benchmark - add this to ContainerPlacementStressTest class.
        Replace the complex run_optimization_benchmark with this.
        """
        if container_counts is None:
            container_counts = [500, 1000, 2000, 5000]
        
        print("🚀 Simple Batch Optimization Benchmark")
        print("=" * 60)
        
        results = {}
        
        for count in container_counts:
            print(f"\n🔧 Testing {count} containers...")
            
            # Create yard and containers
            yard = self.create_test_yard()
            containers = self.generate_random_containers(count)
            
            # Create simple specs
            specs = []
            goods_map = {'Regular': 'reg', 'Reefer': 'r', 'Dangerous': 'dg'}
            
            import random
            for container in containers:
                goods_code = 'sb_t' if container.container_type in ['Swap Body', 'Trailer'] else goods_map.get(container.goods_type, 'reg')
                specs.append({
                    'bay': random.randint(0, yard.n_bays - 1),
                    'goods': goods_code,
                    'container_type': container.container_type,
                    'max_proximity': random.randint(3, 8)
                })
            
            # Run simple benchmark
            result = yard.benchmark_simple_batch(specs)
            results[count] = result
            
            print(f"  Sequential: {result['sequential_time']:.4f}s ({result['sequential_ops_per_sec']:.0f} ops/sec)")
            print(f"  Batch:      {result['batch_time']:.4f}s ({result['batch_ops_per_sec']:.0f} ops/sec)")
            print(f"  Speedup:    {result['speedup']:.2f}x")
            print(f"  Match:      {'✅' if result['results_match'] else '❌'}")
        
        # Summary
        print(f"\n📊 Simple Optimization Summary:")
        for count, result in results.items():
            print(f"  {count} containers: {result['speedup']:.2f}x speedup")
        
        return results